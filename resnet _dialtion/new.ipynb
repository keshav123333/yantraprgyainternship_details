{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52c6b59",
   "metadata": {},
   "source": [
    "### Pranay Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from debugpy import connect\n",
    "from matplotlib import axis\n",
    "from os import name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7713b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x,filters,name):\n",
    "  x=tf.keras.layers.Conv2D(filters=filters,kernel_size=(2,2),padding = 'same',name = f'{name}_CONV2D')(x)\n",
    "  x=tf.keras.layers.MaxPooling2D(pool_size=(2,2),padding = 'same',name = f'{name}_MAXPOOLING2D')(x)\n",
    "  x=tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9,name = f'{name}_BN')(x)\n",
    "  x=tf.keras.layers.Activation(activation='relu',name = f'{name}_RELU')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274414b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling(x,resudial_x,filters,name):\n",
    "  x=tf.keras.layers.Conv2D(filters=filters,kernel_size=(2,2),padding='same',name = f'{name}_CONV2D')(x)\n",
    "  x=tf.keras.layers.UpSampling2D(size=(2,2),name = f'{name}_US')(x)\n",
    "  x=tf.keras.layers.Add(name = f'{name}_ADD')([x,resudial_x])\n",
    "  x=tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9,name = f'{name}_BN')(x)\n",
    "  x=tf.keras.layers.Activation(activation='relu',name = f'{name}_RELU')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSPP(inputs, filters, spatial_shape):\n",
    "    conv1 = tf.keras.layers.Conv2D(\n",
    "        filters=filters, kernel_size=3, dilation_rate=6, padding=\"same\",name=f\"DSPP_conv1_{filters}\"\n",
    "    )(inputs)\n",
    "    conv2 = tf.keras.layers.Conv2D(\n",
    "        filters=filters, kernel_size=3, dilation_rate=12, padding=\"same\",name=f\"DSPP_conv2_{filters}\"\n",
    "    )(inputs)\n",
    "    conv3 = tf.keras.layers.Conv2D(\n",
    "        filters=filters, kernel_size=3, dilation_rate=18, padding=\"same\",name=f\"DSPP_conv3_{filters}\"\n",
    "    )(inputs)\n",
    "    Global2D = tf.keras.layers.GlobalAveragePooling2D(name=f\"DSPP_global2d_{filters}\")(inputs)\n",
    "    x = tf.keras.layers.Reshape((1, 1, -1),name=f\"reshape1_{filters}\")(Global2D)\n",
    "    x = tf.keras.layers.UpSampling2D(size=spatial_shape,name=f\"upsampling2d_{filters}\")(x)\n",
    "    x = tf.keras.layers.Concatenate(axis=-1,name=f\"concat_{filters}\")([conv1, conv2, conv3, x])\n",
    "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, padding=\"same\",name=f\"DSPP_conv_final_{filters}\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9,name=f\"DSPP_bn_{filters}\")(x)\n",
    "    x = tf.keras.layers.Activation(activation='relu',name=f\"DSPP_relu_{filters}\")(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(name = 'UNet'):\n",
    "  inputs=tf.keras.layers.Input(shape=(256,256,3),name = f'{name}_input')\n",
    "  d1  = downsample(inputs,16,name = f'{name}_d1') #128\n",
    "  d2  = downsample(d1,32,name = f'{name}_d2') #64\n",
    "  d3  = downsample(d2,64,name = f'{name}_d3') #32\n",
    "  d4  = downsample(d3,128,name = f'{name}_bottleneck') #16\n",
    "  u3 = upsampling(d4,d3,64,name = f'{name}_u3') #32\n",
    "  u2 = upsampling(u3,d2,32,name = f'{name}_u2') #64\n",
    "  u1 = upsampling(u2,d1,16,name = f'{name}_u1') #128\n",
    "  dspp = DSPP(inputs=u2,filters=32,spatial_shape= (64, 64))\n",
    "  dspp = tf.keras.layers.UpSampling2D(size=(4,4),name= f'{name}_dspp_Upsampling')(dspp)\n",
    "  u0 = tf.keras.layers.UpSampling2D(size=(2,2),name = f'{name}_Upsampling')(u1) \n",
    "  u0 = tf.keras.layers.Concatenate(axis=-1)([u0,dspp]) \n",
    "\n",
    "  outputs = tf.keras.layers.Conv2D(filters=3,kernel_size=(1,1),activation = 'softmax',padding='same',name = f'{name}_outputs')(u0)\n",
    "  model = tf.keras.models.Model(inputs=inputs,outputs=outputs,name=name)\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ff91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_path = \"images/GumsTeethDataSet/OriginalImages/0.jpg\"\n",
    "\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=(256, 256))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  # normalize to [0, 1]\n",
    "img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
    "\n",
    "# Run the image through the model\n",
    "prediction = model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Display the original image and the prediction\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_array[0])\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(prediction[0, :, :, 0], cmap='gray')\n",
    "plt.title(\"Prediction\")\n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71091a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def mask_read_input(folder_path,numberof_datapoint=30):\n",
    "  images = []\n",
    "  folder_names = os.listdir(folder_path)\n",
    "  folder_names= folder_names[:numberof_datapoint]\n",
    "  folder_names.sort()\n",
    "  for folder in folder_names:\n",
    "    img_path_1 = os.path.join(folder_path, folder, 'Teeth.png')\n",
    "    img_1 = tf.io.read_file(img_path_1)\n",
    "    img_1 = tf.image.decode_jpeg(img_1, channels=1)\n",
    "    img_1 = tf.image.resize_with_pad(\n",
    "            img_1,\n",
    "            target_height=256,\n",
    "            target_width=256,\n",
    "            method=tf.image.ResizeMethod.BILINEAR,\n",
    "            antialias=False\n",
    "          )/255\n",
    "    img_path_2 = os.path.join(folder_path, folder, 'Gums.png')\n",
    "    img_2 = tf.io.read_file(img_path_2)\n",
    "    img_2 = tf.image.decode_jpeg(img_2, channels=1)\n",
    "    img_2 = tf.image.resize_with_pad(\n",
    "            img_2,\n",
    "            target_height=256,\n",
    "            target_width=256,\n",
    "            method=tf.image.ResizeMethod.BILINEAR,\n",
    "            antialias=False\n",
    "          )/255\n",
    "    img_3=tf.nn.relu(1.0-(img_1+img_2))\n",
    "    img = tf.concat([img_1, img_2,img_3], axis=-1)\n",
    "    images.append(img)\n",
    "  images_batch = tf.stack(images)\n",
    "  return images_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0896c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def image_read_input(folder_path,numberof_datapoint=30):\n",
    "  images = []\n",
    "  filenames = os.listdir(folder_path)\n",
    "  filenames= filenames[:numberof_datapoint]\n",
    "  filenames.sort()\n",
    "  for filename in filenames:\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize_with_pad(\n",
    "            img,\n",
    "            target_height=256,\n",
    "            target_width=256,\n",
    "            method=tf.image.ResizeMethod.BILINEAR,\n",
    "            antialias=False\n",
    "          )/255\n",
    "    images.append(img)\n",
    "  images_batch = tf.stack(images)\n",
    "  return images_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = mask_read_input(\"images/GumsTeethDataSet/Masks\")\n",
    "batch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aabbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = image_read_input(\"images/GumsTeethDataSet/OriginalImages\")\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices=model.fit(batch, batch_mask, epochs=50, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af422ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e20b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482779f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
